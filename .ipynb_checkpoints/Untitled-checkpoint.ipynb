{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script - Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_MobileNetV2_fft.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import asgparse\n",
    "import os\n",
    "import json\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.applications.mobilenet_v2.mode(include_top = False,\n",
    "                                                       polling ='avg',\n",
    "                                                       weights = 'imagenet',\n",
    "                                                       input_shape = (50,50,3))\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "    ])\n",
    "    model.layers[0].trainable = False\n",
    "    model.compile(\n",
    "        loss = 'binary_crossentropy'\n",
    "        optimizer = 'adam'\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script - Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a train_MobileNetV2_fft.py\n",
    "\n",
    "def create_data_generators(root_dir, batch_size)\n",
    "    train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        horizontal_flip = True,\n",
    "        zoom_range = [0.8 , 1.2]\n",
    "        rotation_range = 45,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=[0.2,1.0]\n",
    "        \n",
    "        \n",
    "    ).flow_from_directory(\n",
    "        os.path.join(root_dir, 'train')\n",
    "        target_size = (50,50)\n",
    "        bacth_size = batch_size,\n",
    "        class_mode = 'binary'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    val_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    ).flow_from_directory(\n",
    "        os.path.join(root_dir, 'val')\n",
    "        target_size = (50,50)\n",
    "        bacth_size = batch_size,\n",
    "        class_mode = 'binary'\n",
    "    )\n",
    "    return train_data_generator, val_data_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script - Putting it Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a train_MobileNetV2_fft.py\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    #hyperparameters arguments\n",
    "    parser.add_argument('--epochs', type = int, default = 3)\n",
    "    parser.add_argument('--batch_size', type = int, default = 16)\n",
    "    parser.add_argument('--steps', type = int, default = int(4243/16))\n",
    "    parser.add_argument('--val_steps', type = int, default = int(1711/16))\n",
    "    \n",
    "    #data channels\n",
    "    parse.add_arguments('--model_dir', type=str)\n",
    "    parse.add_arguments('--sm-model-dir', type=str, default = os.environ.get('SM_MODEL_DIR'))\n",
    "    parse.add_arguments('--train_MobileNetV2_fft', type=str, default = os.environ.get('SM_CHANNEL_TRAINING'))\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    local_output_dir = args.sm_model_dir\n",
    "    local_root_dir = args.train\n",
    "    batch_size = args.batch_size\n",
    "    \n",
    "    model = create_model()\n",
    "    train_gen, val_gen = create_data_generators(root_dir, batch_size) #call create_data_generators\n",
    "    \n",
    "    \n",
    "    _ = model.fit(\n",
    "        train_gen,\n",
    "        epochs = args.epochs,\n",
    "        steps_per_epoch = args.steps,\n",
    "        validation_data = val_gen\n",
    "        validation_steps = args.val_steps \n",
    "    )\n",
    "    \n",
    "    \n",
    "    model.save(os.path.join(local_output_dir, 'model', '2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATH S3 Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket_name = 'pixforce-awsbucket-s3'\n",
    "s3_data_path = 's3://' + bucket_name + '/Data_fft_in_Classes'\n",
    "print('Sess: {}, \\nRole: {}, \\ns3_data_path: {}'.format(sess,role,s3_data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with TensorFlow Estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "MobileNetV2_fft_estimator = TensorFlow(\n",
    "    entry_point='train_MobileNetV2_fft.py',\n",
    "    role=role,\n",
    "    train_instance_type='local_gpu',\n",
    "    train_instance_count=1,\n",
    "    framework_version = '2.1.0',\n",
    "    py_version='py3',\n",
    "    outpath='s3://pixforce-awsbucket-s3/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV2_fft_estimator.fit(s3_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
